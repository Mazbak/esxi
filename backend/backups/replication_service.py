"""
Service pour g√©rer la r√©plication de VMs et le failover entre serveurs ESXi
"""
import logging
import os
import tempfile
import shutil
import requests
import urllib3
import xml.etree.ElementTree as ET
from datetime import datetime
from django.utils import timezone
from pyVim.connect import SmartConnect, Disconnect
from pyVmomi import vim
import ssl
import atexit

from esxi.models import VirtualMachine, ESXiServer
from backups.models import VMReplication, FailoverEvent
from esxi.vmware_service import VMwareService

# D√©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

logger = logging.getLogger(__name__)


class ReplicationService:
    """Service de r√©plication et failover de VMs"""

    def __init__(self):
        self.context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
        self.context.verify_mode = ssl.CERT_NONE

    def _connect_to_server(self, esxi_server):
        """
        √âtablir une connexion √† un serveur ESXi en utilisant VMwareService
        avec pr√©-test de connectivit√© TCP pour environnements multi-interface.

        Args:
            esxi_server: Instance ESXiServer

        Returns:
            ServiceInstance: Connexion pyVmomi

        Raises:
            Exception: Si la connexion √©choue
        """
        try:
            logger.info(f"[REPLICATION] Connexion √† {esxi_server.hostname} via VMwareService...")

            # Utiliser VMwareService qui inclut le pr√©-test TCP et la d√©tection d'interface
            from esxi.vmware_service import VMwareService

            vmware = VMwareService(
                host=esxi_server.hostname,
                user=esxi_server.username,
                password=esxi_server.password,
                port=esxi_server.port or 443
            )

            # Appeler connect() qui fait le pr√©-test TCP automatiquement
            if not vmware.connect(timeout=60):
                raise Exception(f"Impossible de se connecter √† {esxi_server.hostname}")

            logger.info(f"[REPLICATION] Connexion √©tablie √† {esxi_server.hostname}")

            # Retourner le service_instance pour compatibilit√© avec le code existant
            return vmware.service_instance

        except Exception as e:
            logger.error(f"[REPLICATION] Erreur connexion √† {esxi_server.hostname}: {e}")
            raise

    def _get_vm_by_name(self, si, vm_name):
        """
        R√©cup√©rer une VM par son nom

        Args:
            si: ServiceInstance
            vm_name: Nom de la VM

        Returns:
            vim.VirtualMachine ou None
        """
        content = si.RetrieveContent()
        container = content.viewManager.CreateContainerView(
            content.rootFolder, [vim.VirtualMachine], True
        )

        for vm in container.view:
            if vm.name == vm_name:
                container.Destroy()
                return vm

        container.Destroy()
        return None

    def _download_vmdk_with_retry(self, url, local_path, esxi_user, esxi_pass, device_url,
                                    downloaded, file_index, total_size, last_lease_update, last_ui_update,
                                    chunk_counter, lease, progress_callback, replication_id):
        """
        T√©l√©charge un fichier VMDK avec syst√®me de retry automatique en cas d'erreur r√©seau
        Supporte la reprise du t√©l√©chargement avec HTTP Range headers
        Utilise un thread de keepalive pour maintenir le lease ESXi actif

        Returns:
            tuple: (bytes_downloaded, last_lease_update, last_ui_update, chunk_counter, file_size)
        """
        import logging
        import threading
        import time
        logger = logging.getLogger(__name__)

        filename = os.path.basename(device_url.targetId)
        max_retries = 3
        retry_count = 0
        download_complete = False
        file_downloaded = 0
        file_size = 0

        # Thread de keepalive pour maintenir le lease actif
        keepalive_stop = threading.Event()
        keepalive_last_progress = [0]  # Liste pour pouvoir modifier dans le thread

        def lease_keepalive_thread():
            """Thread qui met √† jour le lease toutes les 30 secondes pour √©viter l'expiration"""
            logger.info(f"[KEEPALIVE] Thread de keepalive du lease d√©marr√©")
            while not keepalive_stop.is_set():
                try:
                    # Attendre 30 secondes (ou jusqu'√† ce qu'on demande l'arr√™t)
                    if keepalive_stop.wait(timeout=30):
                        break  # Stop demand√©

                    # Mettre √† jour le lease avec la derni√®re progression connue
                    current_progress = keepalive_last_progress[0]
                    lease.HttpNfcLeaseProgress(current_progress)
                    logger.debug(f"[KEEPALIVE] Lease mis √† jour: {current_progress}%")

                except Exception as e:
                    logger.warning(f"[KEEPALIVE] Erreur lors de la mise √† jour du lease: {e}")

            logger.info(f"[KEEPALIVE] Thread de keepalive arr√™t√©")

        # D√©marrer le thread de keepalive
        keepalive_thread = threading.Thread(target=lease_keepalive_thread, daemon=True)
        keepalive_thread.start()

        try:
            while retry_count <= max_retries and not download_complete:
                download_start_time = time.time()

                try:
                    # V√©rifier si un t√©l√©chargement partiel existe (pour reprise)
                    if os.path.exists(local_path) and os.path.getsize(local_path) > 0 and retry_count > 0:
                        # Reprise du t√©l√©chargement
                        bytes_already_downloaded = os.path.getsize(local_path)
                        file_downloaded = bytes_already_downloaded
                        logger.info(f"[REPLICATION] [RETRY] Reprise √† {bytes_already_downloaded / (1024*1024):.1f} MB (tentative {retry_count + 1}/{max_retries + 1})")

                        response = requests.get(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            stream=True,
                            headers={'Range': f'bytes={bytes_already_downloaded}-'},
                            timeout=(30, 600)  # 30s connexion, 600s (10 min) lecture entre chunks
                        )
                        response.raise_for_status()

                        file_mode = 'ab'  # Append mode
                        file_size_from_header = int(response.headers.get('content-length', 0))
                        if file_size_from_header > 0:
                            file_size = bytes_already_downloaded + file_size_from_header
                    else:
                        # Nouveau t√©l√©chargement
                        bytes_already_downloaded = 0
                        if retry_count > 0:
                            logger.info(f"[REPLICATION] [RETRY] Nouvelle tentative {retry_count + 1}/{max_retries + 1}")

                        response = requests.get(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            stream=True,
                            timeout=(30, 600)  # 30s connexion, 600s (10 min) lecture entre chunks
                        )
                        response.raise_for_status()

                        file_mode = 'wb'  # Write mode
                        file_size = int(response.headers.get('content-length', 0))
                        file_downloaded = 0

                    # Si file_size = 0, utiliser estimation bas√©e sur targetSize
                    if file_size == 0 and hasattr(device_url, 'targetSize') and device_url.targetSize > 0:
                        file_size = device_url.targetSize
                        logger.info(f"[REPLICATION] Utilisation targetSize: {file_size / (1024*1024):.2f} MB")

                    with open(local_path, file_mode) as f:
                        chunk_size = 8192 * 1024  # 8 MB chunks pour meilleure performance r√©seau
                        chunks_received = 0
                        last_speed_update = time.time()
                        speed_mbps = 0

                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                # V√©rifier annulation
                                if replication_id:
                                    from django.core.cache import cache
                                    progress_data = cache.get(f'replication_progress_{replication_id}')
                                    if progress_data and progress_data.get('status') == 'cancelled':
                                        logger.info(f"[REPLICATION] Annulation d√©tect√©e")
                                        raise Exception("R√©plication annul√©e par l'utilisateur")

                                f.write(chunk)
                                downloaded += len(chunk)
                                file_downloaded += len(chunk)
                                chunk_counter += 1
                                chunks_received += 1

                                # Mise √† jour du lease (pour les logs et le keepalive thread)
                                if total_size > 0:
                                    lease_progress = int((downloaded / total_size) * 100)
                                else:
                                    lease_progress = int((file_downloaded / file_size) * 100) if file_size > 0 else 0

                                # Mettre √† jour la progression pour le keepalive thread
                                keepalive_last_progress[0] = lease_progress

                                # Calcul de la vitesse (tous les 2 secondes)
                                current_time = time.time()
                                if current_time - last_speed_update >= 2.0:
                                    elapsed_time = current_time - download_start_time
                                    if elapsed_time > 0:
                                        speed_mbps = (downloaded / (1024 * 1024)) / elapsed_time
                                    last_speed_update = current_time

                                # Calcul progression UI (25-60%)
                                if total_size > 0:
                                    progress_pct = 25 + (35 * downloaded / total_size)
                                else:
                                    if file_size > 0:
                                        progress_pct = 25 + (35 * file_downloaded / file_size)
                                    else:
                                        # Formule am√©lior√©e pour gros fichiers (bas√©e sur vm_backup_service.py)
                                        downloaded_gb = downloaded / (1024 * 1024 * 1024)
                                        if downloaded_gb < 1:
                                            # 0-1 GB: progression de 25% √† 32%
                                            progress_pct = 25 + int(downloaded_gb * 7)
                                        elif downloaded_gb < 5:
                                            # 1-5 GB: progression de 32% √† 40%
                                            progress_pct = 32 + int((downloaded_gb - 1) * 2)
                                        elif downloaded_gb < 10:
                                            # 5-10 GB: progression de 40% √† 47%
                                            progress_pct = 40 + int((downloaded_gb - 5) * 1.4)
                                        elif downloaded_gb < 20:
                                            # 10-20 GB: progression de 47% √† 52%
                                            progress_pct = 47 + int((downloaded_gb - 10) * 0.5)
                                        elif downloaded_gb < 50:
                                            # 20-50 GB: progression de 52% √† 56%
                                            progress_pct = 52 + int((downloaded_gb - 20) * 0.13)
                                        elif downloaded_gb < 100:
                                            # 50-100 GB: progression de 56% √† 58%
                                            progress_pct = 56 + int((downloaded_gb - 50) * 0.04)
                                        elif downloaded_gb < 150:
                                            # 100-150 GB: progression de 58% √† 59%
                                            progress_pct = 58 + int((downloaded_gb - 100) * 0.02)
                                        else:
                                            # 150+ GB: reste √† 59%
                                            progress_pct = 59
                                        progress_pct = min(progress_pct, 60)  # Cap √† 60% max

                                # Arrondir √† l'entier le plus proche pour affichage incr√©mental clair
                                progress_pct_int = int(progress_pct)

                                # Callback UI - Afficher √† chaque nouveau pourcentage entier (1%, 2%, 3%...)
                                if progress_pct_int > int(last_ui_update):
                                    if progress_callback:
                                        downloaded_mb = downloaded / (1024 * 1024)
                                        file_mb = file_downloaded / (1024 * 1024)
                                        file_size_mb = file_size / (1024 * 1024)
                                        speed_str = f" ({speed_mbps:.1f} MB/s)" if speed_mbps > 0 else ""
                                        if total_size > 0:
                                            total_mb = total_size / (1024 * 1024)
                                            progress_callback(progress_pct_int, 'exporting',
                                                f'Export VMDK: {downloaded_mb:.1f}/{total_mb:.1f} MB ({progress_pct_int}%){speed_str}')
                                        elif file_size > 0:
                                            progress_callback(progress_pct_int, 'exporting',
                                                f'Export {filename}: {file_mb:.1f}/{file_size_mb:.1f} MB ({progress_pct_int}%){speed_str}')
                                        else:
                                            progress_callback(progress_pct_int, 'exporting',
                                                f'Export {filename}: {file_mb:.1f} MB{speed_str}')
                                        last_ui_update = progress_pct_int
                                        chunk_counter = 0

                    # T√©l√©chargement r√©ussi!
                    download_complete = True
                    total_time = time.time() - download_start_time
                    avg_speed = (file_downloaded / 1024 / 1024) / total_time if total_time > 0 else 0
                    logger.info(f"[REPLICATION] [OK] {filename} t√©l√©charg√© ({file_downloaded / (1024*1024):.1f} MB en {total_time:.1f}s, {avg_speed:.2f} MB/s)")

                except OSError as e:
                    # G√©rer sp√©cifiquement les erreurs d'espace disque (Errno 28)
                    if e.errno == 28:  # ENOSPC: No space left on device
                        logger.error(f"[REPLICATION] [ERROR] Espace disque insuffisant lors du t√©l√©chargement de {filename}")
                        # Nettoyer le fichier partiel
                        if os.path.exists(local_path):
                            try:
                                os.remove(local_path)
                                logger.info(f"[REPLICATION] Fichier partiel supprim√©: {local_path}")
                            except Exception as cleanup_err:
                                logger.warning(f"[REPLICATION] Erreur nettoyage fichier partiel: {cleanup_err}")
                        raise Exception(
                            f"[Errno 28] No space left on device\n\n"
                            f"Espace disque insuffisant pour t√©l√©charger {filename}. "
                            f"Taille d√©j√† t√©l√©charg√©e: {file_downloaded / (1024*1024):.1f} MB. "
                            f"Lib√©rez de l'espace disque et r√©essayez."
                        )
                    else:
                        # Autre erreur OSError
                        raise

                except (requests.exceptions.ChunkedEncodingError,
                        requests.exceptions.ConnectionError,
                        requests.exceptions.Timeout,
                        ConnectionResetError) as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        logger.error(f"[REPLICATION] [ERROR] √âchec apr√®s {max_retries + 1} tentatives: {e}")
                        # Nettoyer le fichier partiel en cas d'√©chec final
                        if os.path.exists(local_path):
                            try:
                                os.remove(local_path)
                                logger.info(f"[REPLICATION] Fichier partiel supprim√©: {local_path}")
                            except Exception as cleanup_err:
                                logger.warning(f"[REPLICATION] Erreur nettoyage fichier partiel: {cleanup_err}")
                        raise Exception(f"T√©l√©chargement √©chou√© apr√®s {max_retries + 1} tentatives: {e}")

                    logger.warning(f"[REPLICATION] [WARNING] Erreur ({e}), reprise dans 3s...")
                    time.sleep(3)

        finally:
            # IMPORTANT: Arr√™ter le thread de keepalive
            keepalive_stop.set()
            keepalive_thread.join(timeout=5)  # Attendre max 5 secondes

        # Retourner file_downloaded au lieu de file_size car file_size peut √™tre 0 si pas de Content-Length
        return (downloaded, last_lease_update, last_ui_update, chunk_counter, file_downloaded)

    def _export_vm_to_ovf(self, si, vm_name, export_path, esxi_host, esxi_user, esxi_pass, progress_callback=None, replication_id=None):
        """
        Exporter une VM en format OVF en utilisant HttpNfcLease API
        Version simplifi√©e sans d√©pendances sur les mod√®les Django

        Args:
            si: ServiceInstance pyVmomi
            vm_name: Nom de la VM √† exporter
            export_path: Chemin o√π exporter l'OVF
            esxi_host: Hostname du serveur ESXi
            esxi_user: Username ESXi
            esxi_pass: Password ESXi
            progress_callback: Callback optionnel pour progression
            replication_id: ID de r√©plication pour v√©rifier l'annulation

        Returns:
            str: Chemin vers le fichier OVF g√©n√©r√©
        """
        vm_obj = self._get_vm_by_name(si, vm_name)
        if not vm_obj:
            raise Exception(f"VM {vm_name} non trouv√©e")

        logger.info(f"[REPLICATION] D√©but export OVF de {vm_name}")

        # V√âRIFICATION CRITIQUE: D√©tecter les conditions qui emp√™chent l'export
        # 1. V√©rifier si la VM est allum√©e
        power_state = vm_obj.runtime.powerState
        if power_state == vim.VirtualMachinePowerState.poweredOn:
            error_msg = (
                f"La VM '{vm_name}' est actuellement allum√©e (powered on). "
                f"Pour garantir la coh√©rence des donn√©es lors de la r√©plication, "
                f"la VM doit √™tre √©teinte. "
                f"Voulez-vous √©teindre la VM automatiquement ?"
            )
            logger.error(f"[REPLICATION] {error_msg}")
            raise Exception(error_msg)

        # 2. V√©rifier les snapshots
        if vm_obj.snapshot is not None:
            snapshot_count = len(vm_obj.snapshot.rootSnapshotList)
            error_msg = (
                f"La VM '{vm_name}' poss√®de {snapshot_count} snapshot(s). "
                f"L'export OVF n√©cessite de supprimer tous les snapshots. "
                f"Veuillez supprimer les snapshots depuis l'interface ESXi avant de r√©pliquer."
            )
            logger.error(f"[REPLICATION] {error_msg}")
            raise Exception(error_msg)

        # 3. V√©rifier les disques ind√©pendants
        for device in vm_obj.config.hardware.device:
            if isinstance(device, vim.vm.device.VirtualDisk):
                backing = device.backing
                if hasattr(backing, 'diskMode'):
                    if 'independent' in backing.diskMode.lower():
                        error_msg = (
                            f"La VM '{vm_name}' poss√®de des disques en mode 'ind√©pendant'. "
                            f"Les disques ind√©pendants ne peuvent pas √™tre export√©s en OVF. "
                            f"Veuillez convertir les disques en mode 'd√©pendant' depuis l'interface ESXi."
                        )
                        logger.error(f"[REPLICATION] {error_msg}")
                        raise Exception(error_msg)

        logger.info(f"[REPLICATION] V√©rifications pr√©-export r√©ussies pour {vm_name}")

        # Cr√©er un lease d'export
        lease = vm_obj.ExportVm()

        # Attendre que le lease soit pr√™t
        while lease.state == vim.HttpNfcLease.State.initializing:
            pass

        if lease.state != vim.HttpNfcLease.State.ready:
            raise Exception(f"Export lease √©chou√©: {lease.state}")

        try:
            # T√©l√©charger les fichiers VMDK
            vmdk_files = []
            device_urls = lease.info.deviceUrl

            # Calculer total_size depuis l'API si disponible
            total_size = sum(d.targetSize for d in device_urls if hasattr(d, 'targetSize'))

            # Si total_size = 0 (m√©tadonn√©es incompl√®tes), faire une passe pour r√©cup√©rer les tailles r√©elles
            if total_size == 0:
                logger.info(f"[REPLICATION] targetSize non disponible, r√©cup√©ration tailles r√©elles via HTTP HEAD...")
                for device_url in device_urls:
                    if not device_url.url.endswith('.vmdk'):
                        continue
                    url = device_url.url.replace('*', esxi_host)
                    try:
                        # HEAD request pour obtenir Content-Length sans t√©l√©charger
                        head_response = requests.head(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            timeout=10
                        )
                        file_size = int(head_response.headers.get('content-length', 0))
                        total_size += file_size
                    except Exception as e:
                        logger.warning(f"[REPLICATION] Impossible de r√©cup√©rer la taille de {url}: {e}")

                logger.info(f"[REPLICATION] Taille totale calcul√©e depuis HTTP: {total_size / (1024*1024):.2f} MB")
            else:
                logger.info(f"[REPLICATION] Taille totale depuis API: {total_size / (1024*1024):.2f} MB")

            downloaded = 0
            last_lease_update = 0  # Dernier pourcentage o√π on a mis √† jour le lease
            last_ui_update = 0  # Dernier pourcentage o√π on a mis √† jour l'UI
            chunk_counter = 0  # Compteur de chunks

            file_index = 0
            for device_url in device_urls:
                if not device_url.url.endswith('.vmdk'):
                    continue

                # Remplacer * par l'IP du serveur ESXi
                url = device_url.url.replace('*', esxi_host)
                filename = os.path.basename(device_url.targetId)
                local_path = os.path.join(export_path, filename)

                logger.info(f"[REPLICATION] T√©l√©chargement {filename}...")

                # Utiliser la m√©thode avec retry automatique et reprise
                downloaded, last_lease_update, last_ui_update, chunk_counter, file_size = self._download_vmdk_with_retry(
                    url=url,
                    local_path=local_path,
                    esxi_user=esxi_user,
                    esxi_pass=esxi_pass,
                    device_url=device_url,
                    downloaded=downloaded,
                    file_index=file_index,
                    total_size=total_size,
                    last_lease_update=last_lease_update,
                    last_ui_update=last_ui_update,
                    chunk_counter=chunk_counter,
                    lease=lease,
                    progress_callback=progress_callback,
                    replication_id=replication_id
                )

                vmdk_files.append({
                    'path': local_path,
                    'filename': filename,
                    'size': file_size
                })
                logger.info(f"[REPLICATION] {filename} t√©l√©charg√©: {file_size / (1024*1024):.2f} MB")
                file_index += 1

            # Cr√©er le descripteur OVF
            ovf_path = os.path.join(export_path, f"{vm_name}.ovf")
            self._create_simple_ovf_descriptor(vm_obj, vmdk_files, ovf_path)

            # Compl√©ter le lease seulement s'il est encore actif
            try:
                if lease.state == vim.HttpNfcLease.State.ready:
                    lease.HttpNfcLeaseComplete()
                    logger.info(f"[REPLICATION] Lease compl√©t√© avec succ√®s")
            except Exception as lease_err:
                logger.warning(f"[REPLICATION] Impossible de compl√©ter le lease (probablement d√©j√† ferm√©): {lease_err}")

            logger.info(f"[REPLICATION] Export OVF termin√©: {ovf_path}")
            return ovf_path

        except Exception as e:
            # Annuler le lease seulement s'il est encore actif
            try:
                if lease.state in [vim.HttpNfcLease.State.ready, vim.HttpNfcLease.State.initializing]:
                    lease.HttpNfcLeaseAbort()
            except:
                pass  # Ignorer les erreurs lors de l'annulation
            raise

    def _create_simple_ovf_descriptor(self, vm_obj, vmdk_files, ovf_path):
        """Cr√©er un descripteur OVF valide avec contr√¥leur SCSI et disques"""
        import xml.etree.ElementTree as ET

        # Namespaces
        namespaces = {
            'ovf': 'http://schemas.dmtf.org/ovf/envelope/1',
            'rasd': 'http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_ResourceAllocationSettingData',
            'vssd': 'http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_VirtualSystemSettingData',
            'vmw': 'http://www.vmware.com/schema/ovf'
        }

        for prefix, uri in namespaces.items():
            ET.register_namespace(prefix, uri)

        # Cr√©er le root element
        root = ET.Element(f"{{{namespaces['ovf']}}}Envelope",
                         attrib={
                             f"{{{namespaces['ovf']}}}version": "1.0",
                             "xml:lang": "en-US"
                         })

        # References Section
        references = ET.SubElement(root, f"{{{namespaces['ovf']}}}References")
        for vmdk in vmdk_files:
            file_elem = ET.SubElement(references, f"{{{namespaces['ovf']}}}File",
                                     attrib={
                                         f"{{{namespaces['ovf']}}}href": vmdk['filename'],
                                         f"{{{namespaces['ovf']}}}id": f"file-{vmdk['filename']}",
                                         f"{{{namespaces['ovf']}}}size": str(vmdk['size'])
                                     })

        # DiskSection
        disk_section = ET.SubElement(root, f"{{{namespaces['ovf']}}}DiskSection")
        ET.SubElement(disk_section, f"{{{namespaces['ovf']}}}Info").text = "Virtual disk information"

        for i, vmdk in enumerate(vmdk_files):
            # Capacit√© en bytes - convertir de bytes √† bytes (d√©j√† en bytes)
            capacity_bytes = vmdk['size']
            # L'attribut capacity attend des unit√©s d'allocation, utilisons bytes
            disk = ET.SubElement(disk_section, f"{{{namespaces['ovf']}}}Disk",
                                attrib={
                                    f"{{{namespaces['ovf']}}}capacity": str(capacity_bytes),
                                    f"{{{namespaces['ovf']}}}capacityAllocationUnits": "byte",
                                    f"{{{namespaces['ovf']}}}diskId": f"vmdisk{i+1}",
                                    f"{{{namespaces['ovf']}}}fileRef": f"file-{vmdk['filename']}",
                                    f"{{{namespaces['ovf']}}}format": "http://www.vmware.com/interfaces/specifications/vmdk.html#streamOptimized"
                                })

        # NetworkSection
        network_section = ET.SubElement(root, f"{{{namespaces['ovf']}}}NetworkSection")
        ET.SubElement(network_section, f"{{{namespaces['ovf']}}}Info").text = "Logical networks"
        network = ET.SubElement(network_section, f"{{{namespaces['ovf']}}}Network",
                               attrib={f"{{{namespaces['ovf']}}}name": "VM Network"})
        ET.SubElement(network, f"{{{namespaces['ovf']}}}Description").text = "VM Network"

        # VirtualSystem
        vs = ET.SubElement(root, f"{{{namespaces['ovf']}}}VirtualSystem",
                          attrib={f"{{{namespaces['ovf']}}}id": vm_obj.name})

        ET.SubElement(vs, f"{{{namespaces['ovf']}}}Info").text = f"A virtual machine"
        ET.SubElement(vs, f"{{{namespaces['ovf']}}}Name").text = vm_obj.name

        # VirtualHardwareSection
        vhw = ET.SubElement(vs, f"{{{namespaces['ovf']}}}VirtualHardwareSection")
        ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Info").text = "Virtual hardware requirements"

        # System (obligatoire)
        system = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}System")
        ET.SubElement(system, f"{{{namespaces['vssd']}}}ElementName").text = "Virtual Hardware Family"
        ET.SubElement(system, f"{{{namespaces['vssd']}}}InstanceID").text = "0"
        ET.SubElement(system, f"{{{namespaces['vssd']}}}VirtualSystemType").text = "vmx-11"

        # CPU
        item_cpu = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Item")
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}AllocationUnits").text = "hertz * 10^6"
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}Description").text = "Number of Virtual CPUs"
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}ElementName").text = "1 virtual CPU(s)"
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}InstanceID").text = "1"
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}ResourceType").text = "3"
        ET.SubElement(item_cpu, f"{{{namespaces['rasd']}}}VirtualQuantity").text = "1"

        # Memory
        item_mem = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Item")
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}AllocationUnits").text = "byte * 2^20"
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}Description").text = "Memory Size"
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}ElementName").text = "2048MB of memory"
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}InstanceID").text = "2"
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}ResourceType").text = "4"
        ET.SubElement(item_mem, f"{{{namespaces['rasd']}}}VirtualQuantity").text = "2048"

        # Contr√¥leur SCSI (OBLIGATOIRE pour les disques!)
        item_scsi = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Item")
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}Address").text = "0"
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}Description").text = "SCSI Controller"
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}ElementName").text = "SCSI Controller 0"
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}InstanceID").text = "3"
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}ResourceSubType").text = "lsilogic"
        ET.SubElement(item_scsi, f"{{{namespaces['rasd']}}}ResourceType").text = "6"

        # Disques (r√©f√©rencent le contr√¥leur SCSI)
        for i, vmdk in enumerate(vmdk_files):
            item_disk = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Item")
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}AddressOnParent").text = str(i)
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}Description").text = "Hard disk"
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}ElementName").text = f"Hard Disk {i+1}"
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}HostResource").text = f"ovf:/disk/vmdisk{i+1}"
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}InstanceID").text = str(4 + i)
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}Parent").text = "3"  # R√©f√©rence au contr√¥leur SCSI
            ET.SubElement(item_disk, f"{{{namespaces['rasd']}}}ResourceType").text = "17"

        # Network adapter
        item_net = ET.SubElement(vhw, f"{{{namespaces['ovf']}}}Item")
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}AddressOnParent").text = "7"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}AutomaticAllocation").text = "true"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}Connection").text = "VM Network"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}Description").text = "E1000 ethernet adapter"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}ElementName").text = "Network adapter 1"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}InstanceID").text = str(4 + len(vmdk_files))
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}ResourceSubType").text = "E1000"
        ET.SubElement(item_net, f"{{{namespaces['rasd']}}}ResourceType").text = "10"

        # √âcrire le fichier OVF
        tree = ET.ElementTree(root)
        ET.indent(tree, space="  ")  # Pretty print
        tree.write(ovf_path, encoding='utf-8', xml_declaration=True)

        logger.info(f"[REPLICATION] Descripteur OVF cr√©√©: {ovf_path}")

        # Logger la taille des disques pour debug
        for vmdk in vmdk_files:
            logger.info(f"[REPLICATION] VMDK dans OVF: {vmdk['filename']} - {vmdk['size'] / (1024*1024):.2f} MB")

    def replicate_vm(self, replication, progress_callback=None, replication_id=None):
        """
        Effectuer une r√©plication compl√®te de VM

        Processus :
        1. Exporter la VM source en OVF (temporaire)
        2. D√©ployer sur le serveur destination avec suffix "_replica"
        3. La VM replica est pr√™te pour le failover instantan√©

        Args:
            replication: Instance VMReplication
            progress_callback: Fonction callback pour la progression (optionnel)
            replication_id: ID de r√©plication pour v√©rifier l'annulation (optionnel)

        Returns:
            dict: R√©sultat de la r√©plication
        """
        temp_dir = None
        try:
            import time
            start_time = timezone.now()
            logger.info(f"[REPLICATION] D√©marrage: {replication.name}")

            if progress_callback:
                progress_callback(0, 'starting', 'D√©marrage de la r√©plication...')

            source_server = replication.get_source_server
            destination_server = replication.destination_server
            vm_name = replication.virtual_machine.name
            replica_vm_name = f"{vm_name}_replica"

            # Progression graduelle 1-24% (affichage incr√©mental clair)
            if progress_callback:
                for pct in range(1, 3):
                    progress_callback(pct, 'initializing', f'Initialisation de la r√©plication... {pct}%')
                    time.sleep(0.1)

            # V√©rifier si la VM replica existe d√©j√† (3-8%)
            logger.info(f"[REPLICATION] Connexion au serveur destination: {destination_server.hostname}")
            if progress_callback:
                for pct in range(3, 6):
                    progress_callback(pct, 'connecting', f'Connexion au serveur destination... {pct}%')
                    time.sleep(0.1)

            dest_si = self._connect_to_server(destination_server)

            if progress_callback:
                progress_callback(6, 'checking', 'V√©rification de la VM replica existante... 6%')
                progress_callback(7, 'checking', 'V√©rification de la VM replica existante... 7%')

            existing_replica = self._get_vm_by_name(dest_si, replica_vm_name)

            if existing_replica:
                logger.info(f"[REPLICATION] VM replica existe d√©j√†: {replica_vm_name}")
                logger.info(f"[REPLICATION] Suppression de l'ancienne replica pour mise √† jour...")

                if progress_callback:
                    for pct in range(8, 11):
                        progress_callback(pct, 'cleaning', f'Pr√©paration de la suppression... {pct}%')
                        time.sleep(0.1)

                # Arr√™ter la VM si elle tourne
                if existing_replica.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                    if progress_callback:
                        progress_callback(11, 'cleaning', 'Arr√™t de l\'ancienne VM replica... 11%')
                    power_off_task = existing_replica.PowerOffVM_Task()
                    while power_off_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                        time.sleep(0.1)

                # Supprimer la VM
                if progress_callback:
                    for pct in range(12, 15):
                        progress_callback(pct, 'cleaning', f'Suppression des fichiers de la replica... {pct}%')
                        time.sleep(0.1)
                destroy_task = existing_replica.Destroy_Task()
                while destroy_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    time.sleep(0.1)

                logger.info(f"[REPLICATION] Ancienne replica supprim√©e")
                if progress_callback:
                    progress_callback(15, 'cleaned', 'Ancienne replica supprim√©e - 15%')
            else:
                # Pas de replica existante, progression rapide mais visible
                if progress_callback:
                    for pct in range(8, 16):
                        progress_callback(pct, 'checking', f'Aucune replica existante - Pr√©paration... {pct}%')
                        time.sleep(0.1)

            # Cr√©er un r√©pertoire temporaire pour l'export OVF (16-18%)
            if progress_callback:
                for pct in range(16, 19):
                    progress_callback(pct, 'preparing', f'Cr√©ation du r√©pertoire temporaire... {pct}%')
                    time.sleep(0.1)

            temp_dir = tempfile.mkdtemp(prefix='replication_')
            logger.info(f"[REPLICATION] R√©pertoire temporaire: {temp_dir}")

            # Se connecter au serveur source pour l'export (19-24%)
            logger.info(f"[REPLICATION] Connexion au serveur source: {source_server.hostname}")
            if progress_callback:
                for pct in range(19, 23):
                    progress_callback(pct, 'connecting', f'Connexion au serveur source... {pct}%')
                    time.sleep(0.1)

            source_si = self._connect_to_server(source_server)

            if progress_callback:
                for pct in range(23, 25):
                    progress_callback(pct, 'connected', f'Serveur source connect√© - Pr√©paration... {pct}%')
                    time.sleep(0.1)

            # Exporter la VM source en OVF (25% ‚Üí 60%)
            logger.info(f"[REPLICATION] Export de la VM source: {vm_name}")
            if progress_callback:
                progress_callback(25, 'exporting', f'Export de la VM {vm_name} en cours...')

            ovf_path = self._export_vm_to_ovf(
                source_si,
                vm_name,
                temp_dir,
                source_server.hostname,
                source_server.username,
                source_server.password,
                progress_callback,
                replication_id
            )
            logger.info(f"[REPLICATION] Export OVF termin√©: {ovf_path}")

            if progress_callback:
                for pct in range(60, 63):
                    progress_callback(pct, 'exported', f'Export OVF termin√© avec succ√®s - {pct}%')
                    time.sleep(0.1)

            # D√©connexion du serveur source
            Disconnect(source_si)

            # D√©ployer sur le serveur destination avec le nom "_replica" (63-70%)
            logger.info(f"[REPLICATION] D√©ploiement sur serveur destination: {destination_server.hostname}")
            if progress_callback:
                for pct in range(63, 66):
                    progress_callback(pct, 'deploying', f'Pr√©paration du d√©ploiement... {pct}%')
                    time.sleep(0.1)

            vmware_service = VMwareService(
                host=destination_server.hostname,
                user=destination_server.username,
                password=destination_server.password,
                port=destination_server.port or 443
            )

            # SE CONNECTER au serveur de destination
            logger.info(f"[REPLICATION] Connexion au serveur de destination {destination_server.hostname}...")
            if progress_callback:
                for pct in range(66, 69):
                    progress_callback(pct, 'deploying', f'Connexion au serveur de destination... {pct}%')
                    time.sleep(0.1)

            if not vmware_service.connect():
                raise Exception(f"Impossible de se connecter au serveur de destination {destination_server.hostname}")
            logger.info(f"[REPLICATION] [OK] Connect√© au serveur de destination")

            # Utiliser le datastore configur√© dans la r√©plication (69-73%)
            if progress_callback:
                for pct in range(69, 73):
                    progress_callback(pct, 'deploying', f'V√©rification du datastore de destination... {pct}%')
                    time.sleep(0.1)

            dest_datastore = replication.destination_datastore
            logger.info(f"[REPLICATION] Datastore de destination configur√©: {dest_datastore}")

            # V√©rifier que le datastore existe sur le serveur de destination
            logger.info(f"[REPLICATION] V√©rification du datastore sur {destination_server.hostname}...")
            try:
                datastores_info = vmware_service.get_datastores()
                logger.info(f"[REPLICATION] Datastores disponibles: {[ds['name'] for ds in datastores_info]}")

                # V√©rifier que le datastore configur√© existe
                datastore_found = False
                for ds in datastores_info:
                    if ds['name'] == dest_datastore:
                        datastore_found = True
                        logger.info(f"[REPLICATION] ‚úì Datastore {dest_datastore} trouv√© (capacit√©: {ds['capacity_gb']} GB, libre: {ds['free_space_gb']} GB)")
                        break

                if not datastore_found:
                    raise Exception(f"Le datastore '{dest_datastore}' n'existe pas sur le serveur {destination_server.hostname}. Datastores disponibles: {[ds['name'] for ds in datastores_info]}")

            except Exception as ds_err:
                logger.error(f"[REPLICATION] Erreur lors de la v√©rification du datastore: {ds_err}", exc_info=True)
                raise Exception(f"Erreur v√©rification datastore: {ds_err}")

            # D√©ployer l'OVF (73% ‚Üí 90%)
            if progress_callback:
                for pct in range(73, 76):
                    progress_callback(pct, 'deploying', f'D√©but du d√©ploiement de l\'OVF... {pct}%')
                    time.sleep(0.1)

            # Cr√©er un callback wrapper pour mapper 0-100% du d√©ploiement vers 76-90% de la progression totale
            def deploy_progress_callback(deploy_pct, status='deploying', message='D√©ploiement en cours...'):
                if progress_callback:
                    # Mapper 0-100% du d√©ploiement vers 76-90% de la progression totale
                    total_pct = int(76 + (14 * deploy_pct / 100))
                    progress_callback(total_pct, status, f'{message} - {total_pct}%')

            logger.info(f"[REPLICATION] D√©ploiement OVF avec support d'annulation (replication_id={replication_id})")

            deploy_success = vmware_service.deploy_ovf(
                ovf_path=ovf_path,
                vm_name=replica_vm_name,
                datastore_name=dest_datastore,
                network_name='VM Network',
                power_on=False,  # Ne pas d√©marrer la replica automatiquement
                progress_callback=deploy_progress_callback,
                restore_id=replication_id,  # Utiliser replication_id pour v√©rifier les annulations
                disk_provisioning='thin'  # Forcer thin provisioning pour √©conomiser l'espace
            )

            if not deploy_success:
                raise Exception("√âchec du d√©ploiement OVF sur le serveur destination")

            logger.info(f"[REPLICATION] VM replica d√©ploy√©e: {replica_vm_name}")

            if progress_callback:
                for pct in range(90, 93):
                    progress_callback(pct, 'deployed', f'VM replica {replica_vm_name} d√©ploy√©e - {pct}%')
                    time.sleep(0.1)

            # Nettoyer le r√©pertoire temporaire (93-96%)
            if progress_callback:
                for pct in range(93, 96):
                    progress_callback(pct, 'cleaning', f'Suppression des fichiers temporaires... {pct}%')
                    time.sleep(0.1)

            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                logger.info(f"[REPLICATION] R√©pertoire temporaire nettoy√©")

            if progress_callback:
                progress_callback(96, 'cleaned', 'Nettoyage termin√© - 96%')
                progress_callback(97, 'updating', 'Mise √† jour des m√©tadonn√©es... 97%')

            end_time = timezone.now()
            duration = (end_time - start_time).total_seconds()

            replication.last_replication_at = end_time
            replication.last_replication_duration_seconds = int(duration)
            replication.status = 'active'
            replication.save()

            logger.info(f"[REPLICATION] Termin√©e: {replication.name} ({duration:.2f}s)")

            if progress_callback:
                progress_callback(98, 'saving', 'Enregistrement de l\'√©tat de r√©plication... 98%')
                time.sleep(0.1)
                progress_callback(99, 'disconnecting', 'D√©connexion des serveurs... 99%')

            # D√©connexion
            Disconnect(dest_si)

            if progress_callback:
                time.sleep(0.2)
                progress_callback(100, 'completed', f'[OK] R√©plication termin√©e avec succ√®s en {duration:.1f}s - 100%')

            # D√©connecter le service VMware de destination
            try:
                vmware_service.disconnect()
                logger.info(f"[REPLICATION] D√©connect√© du serveur de destination")
            except:
                pass

            return {
                'success': True,
                'duration_seconds': duration,
                'message': f"R√©plication de {vm_name} termin√©e avec succ√®s. VM replica: {replica_vm_name}"
            }

        except Exception as e:
            logger.error(f"[REPLICATION] Erreur: {replication.name}: {e}")

            # D√©tecter l'erreur d'espace disque insuffisant
            error_message = str(e)
            if '[Errno 28]' in error_message or 'No space left on device' in error_message:
                # Message d'erreur clair et actionnable pour l'utilisateur
                user_message = (
                    "‚ùå Espace disque insuffisant\n\n"
                    "Le disque contenant les fichiers temporaires est plein. "
                    "La r√©plication n√©cessite de l'espace disque temporaire pour exporter la VM.\n\n"
                    "üí° Solutions possibles :\n"
                    "‚Ä¢ Lib√©rer de l'espace disque sur le serveur (supprimer fichiers inutiles, vider /tmp)\n"
                    "‚Ä¢ Nettoyer les anciennes sauvegardes et exports OVF\n"
                    "‚Ä¢ V√©rifier l'espace disponible avec : df -h /tmp\n"
                    "‚Ä¢ Configurer un r√©pertoire temporaire sur un disque avec plus d'espace"
                )
                detailed_error = (
                    f"Espace disque insuffisant pour cr√©er les fichiers temporaires de r√©plication. "
                    f"R√©pertoire temporaire : {temp_dir if temp_dir else '/tmp'}. "
                    f"Lib√©rez de l'espace disque et r√©essayez."
                )
            else:
                user_message = f"Erreur: {error_message}"
                detailed_error = error_message

            if progress_callback:
                progress_callback(-1, 'error', user_message)

            # D√©connecter le service VMware de destination si cr√©√©
            try:
                if 'vmware_service' in locals():
                    vmware_service.disconnect()
                    logger.info(f"[REPLICATION] D√©connect√© du serveur de destination (erreur)")
            except:
                pass

            # Nettoyer le r√©pertoire temporaire en cas d'erreur
            if temp_dir and os.path.exists(temp_dir):
                try:
                    shutil.rmtree(temp_dir)
                except:
                    pass

            replication.status = 'error'
            replication.save()

            return {
                'success': False,
                'error': detailed_error,
                'message': user_message
            }

    def execute_failover(self, failover_event, test_mode=False):
        """
        Ex√©cuter un failover (basculement)

        Args:
            failover_event: Instance FailoverEvent
            test_mode: Si True, ne pas arr√™ter la VM source

        Returns:
            dict: R√©sultat du failover
        """
        try:
            logger.info(f"D√©marrage failover: {failover_event.id}")
            failover_event.status = 'in_progress'
            failover_event.save()

            replication = failover_event.replication
            source_server = replication.get_source_server
            destination_server = replication.destination_server
            vm_name = replication.virtual_machine.name

            # Se connecter aux serveurs
            logger.info(f"Connexion au serveur source: {source_server.hostname}")
            source_si = self._connect_to_server(source_server)

            logger.info(f"Connexion au serveur destination: {destination_server.hostname}")
            dest_si = self._connect_to_server(destination_server)

            # R√©cup√©rer les VMs
            source_vm = self._get_vm_by_name(source_si, vm_name)
            dest_vm = self._get_vm_by_name(dest_si, f"{vm_name}_replica")

            if not dest_vm:
                # Si la VM de destination n'existe pas, utiliser le m√™me nom
                dest_vm = self._get_vm_by_name(dest_si, vm_name)

            if not dest_vm:
                raise Exception(f"VM de destination non trouv√©e sur {destination_server.hostname}")

            # Arr√™ter la VM source (sauf en mode test)
            if source_vm and source_vm.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                if not test_mode:
                    logger.info(f"Arr√™t de la VM source: {vm_name}")
                    power_off_task = source_vm.PowerOffVM_Task()

                    # Attendre la fin de l'arr√™t
                    while power_off_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                        pass

                    if power_off_task.info.state == vim.TaskInfo.State.error:
                        raise Exception(f"Erreur arr√™t VM source: {power_off_task.info.error}")

                    failover_event.source_vm_powered_off = True
                    failover_event.save()
                    logger.info(f"VM source arr√™t√©e: {vm_name}")
                else:
                    logger.info(f"Mode test: VM source non arr√™t√©e")

            # D√©marrer la VM de destination
            if dest_vm.runtime.powerState != vim.VirtualMachinePowerState.poweredOn:
                logger.info(f"D√©marrage de la VM de destination: {vm_name}")
                power_on_task = dest_vm.PowerOnVM_Task()

                # Attendre le d√©marrage
                while power_on_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    pass

                if power_on_task.info.state == vim.TaskInfo.State.error:
                    raise Exception(f"Erreur d√©marrage VM destination: {power_on_task.info.error}")

                failover_event.destination_vm_powered_on = True
                failover_event.save()
                logger.info(f"VM de destination d√©marr√©e: {vm_name}")
            else:
                logger.info(f"VM de destination d√©j√† d√©marr√©e: {vm_name}")
                failover_event.destination_vm_powered_on = True
                failover_event.save()

            # Marquer le failover comme termin√©
            failover_event.status = 'completed'
            failover_event.completed_at = timezone.now()
            failover_event.save()

            # Activer le flag failover_active sur la r√©plication
            replication.failover_active = True
            replication.save()
            logger.info(f"Failover actif marqu√© pour r√©plication {replication.id}")

            # D√©connexion
            Disconnect(source_si)
            Disconnect(dest_si)

            logger.info(f"Failover termin√© avec succ√®s: {failover_event.id}")

            return {
                'success': True,
                'message': f"Failover de {vm_name} termin√© avec succ√®s",
                'source_powered_off': failover_event.source_vm_powered_off,
                'destination_powered_on': failover_event.destination_vm_powered_on
            }

        except Exception as e:
            logger.error(f"Erreur lors du failover {failover_event.id}: {e}")

            failover_event.status = 'failed'
            failover_event.error_message = str(e)
            failover_event.completed_at = timezone.now()
            failover_event.save()

            return {
                'success': False,
                'error': str(e),
                'message': f"Erreur lors du failover: {e}"
            }

    def check_and_trigger_auto_failover(self, replication):
        """
        V√©rifier si un failover automatique doit √™tre d√©clench√©

        Args:
            replication: Instance VMReplication

        Returns:
            dict: R√©sultat de la v√©rification
        """
        if replication.failover_mode != 'automatic':
            return {'should_failover': False, 'reason': 'Mode automatique non activ√©'}

        # V√©rifier si le serveur source est indisponible
        source_server = replication.get_source_server

        try:
            # Tenter de se connecter au serveur source
            si = self._connect_to_server(source_server)

            # V√©rifier la VM
            vm = self._get_vm_by_name(si, replication.virtual_machine.name)

            if not vm:
                return {'should_failover': False, 'reason': 'VM non trouv√©e'}

            # V√©rifier l'√©tat de la VM
            if vm.runtime.powerState != vim.VirtualMachinePowerState.poweredOn:
                # VM √©teinte, v√©rifier le d√©lai
                if replication.last_replication_at:
                    minutes_since_last = (timezone.now() - replication.last_replication_at).total_seconds() / 60

                    if minutes_since_last >= replication.auto_failover_threshold_minutes:
                        return {
                            'should_failover': True,
                            'reason': f'VM √©teinte depuis {minutes_since_last:.0f} minutes'
                        }

            Disconnect(si)
            return {'should_failover': False, 'reason': 'VM en fonctionnement normal'}

        except Exception as e:
            logger.error(f"Erreur v√©rification auto-failover pour {replication.name}: {e}")

            # Serveur source inaccessible
            if replication.last_replication_at:
                minutes_since_last = (timezone.now() - replication.last_replication_at).total_seconds() / 60

                if minutes_since_last >= replication.auto_failover_threshold_minutes:
                    return {
                        'should_failover': True,
                        'reason': f'Serveur source inaccessible depuis {minutes_since_last:.0f} minutes'
                    }

            return {'should_failover': False, 'reason': f'Serveur source inaccessible (en attente du d√©lai): {e}'}

    def execute_failback(self, replication, triggered_by=None):
        """
        Ex√©cuter un failback (retour √† la normale)
        Arr√™te la VM slave (destination) et rallume la VM master (source)

        Args:
            replication: Instance VMReplication
            triggered_by: User ayant d√©clench√© le failback (None si automatique)

        Returns:
            dict: R√©sultat du failback
        """
        try:
            logger.info(f"[FAILBACK] === D√âBUT FAILBACK pour r√©plication {replication.id} ===")

            if not replication.failover_active:
                logger.warning(f"[FAILBACK] Aucun failover actif pour {replication.name}")
                return {
                    'success': False,
                    'error': 'Aucun failover actif',
                    'message': 'Aucun failover actif pour cette r√©plication'
                }

            source_server = replication.get_source_server
            destination_server = replication.destination_server
            vm_name = replication.virtual_machine.name
            replica_vm_name = f"{vm_name}_replica"

            # Se connecter aux serveurs
            logger.info(f"[FAILBACK] Connexion au serveur source: {source_server.hostname}")
            source_si = self._connect_to_server(source_server)

            logger.info(f"[FAILBACK] Connexion au serveur destination: {destination_server.hostname}")
            dest_si = self._connect_to_server(destination_server)

            # R√©cup√©rer les VMs
            source_vm = self._get_vm_by_name(source_si, vm_name)
            dest_vm = self._get_vm_by_name(dest_si, replica_vm_name)

            if not dest_vm:
                # Si la VM de destination n'existe pas avec _replica, chercher avec le nom normal
                dest_vm = self._get_vm_by_name(dest_si, vm_name)

            if not source_vm:
                logger.error(f"[FAILBACK] VM source non trouv√©e: {vm_name}")
                Disconnect(source_si)
                Disconnect(dest_si)
                return {
                    'success': False,
                    'error': 'VM source non trouv√©e',
                    'message': f'VM source {vm_name} non trouv√©e sur {source_server.hostname}'
                }

            # Arr√™ter la VM slave (destination)
            if dest_vm and dest_vm.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                logger.info(f"[FAILBACK] Arr√™t de la VM slave: {replica_vm_name}")
                power_off_task = dest_vm.PowerOffVM_Task()

                # Attendre la fin de l'arr√™t
                while power_off_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    pass

                if power_off_task.info.state == vim.TaskInfo.State.error:
                    raise Exception(f"Erreur arr√™t VM slave: {power_off_task.info.error}")

                logger.info(f"[FAILBACK] VM slave arr√™t√©e: {replica_vm_name}")
            else:
                logger.info(f"[FAILBACK] VM slave d√©j√† arr√™t√©e ou inexistante")

            # Red√©marrer la VM master (source)
            if source_vm.runtime.powerState != vim.VirtualMachinePowerState.poweredOn:
                logger.info(f"[FAILBACK] D√©marrage de la VM master: {vm_name}")
                power_on_task = source_vm.PowerOnVM_Task()

                # Attendre le d√©marrage
                while power_on_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    pass

                if power_on_task.info.state == vim.TaskInfo.State.error:
                    raise Exception(f"Erreur d√©marrage VM master: {power_on_task.info.error}")

                logger.info(f"[FAILBACK] VM master d√©marr√©e: {vm_name}")
            else:
                logger.info(f"[FAILBACK] VM master d√©j√† d√©marr√©e: {vm_name}")

            # D√©sactiver le flag failover_active
            replication.failover_active = False
            replication.save()
            logger.info(f"[FAILBACK] Failover d√©sactiv√© pour r√©plication {replication.id}")

            # D√©connexion
            Disconnect(source_si)
            Disconnect(dest_si)

            logger.info(f"[FAILBACK] === FAILBACK TERMIN√â AVEC SUCC√àS ===")

            return {
                'success': True,
                'message': f"Failback de {vm_name} termin√© avec succ√®s. VM master rallum√©e, VM slave arr√™t√©e.",
                'master_powered_on': True,
                'slave_powered_off': True
            }

        except Exception as e:
            logger.error(f"[FAILBACK] ‚úó Erreur lors du failback: {e}", exc_info=True)

            return {
                'success': False,
                'error': str(e),
                'message': f"Erreur lors du failback: {e}"
            }

    def check_and_trigger_auto_failback(self, replication):
        """
        V√©rifier si un failback automatique doit √™tre d√©clench√©
        (quand master revient en ligne apr√®s un failover)

        Args:
            replication: Instance VMReplication

        Returns:
            dict: R√©sultat de la v√©rification
        """
        # V√©rifier que le failback automatique est activ√©
        if not replication.failback_enabled:
            return {'should_failback': False, 'reason': 'Failback automatique d√©sactiv√©'}

        # V√©rifier qu'un failover est actuellement actif
        if not replication.failover_active:
            return {'should_failback': False, 'reason': 'Aucun failover actif'}

        # V√©rifier que la VM master est revenue en ligne
        source_server = replication.get_source_server

        try:
            # Tenter de se connecter au serveur source
            si = self._connect_to_server(source_server)

            # V√©rifier la VM
            vm = self._get_vm_by_name(si, replication.virtual_machine.name)

            if not vm:
                Disconnect(si)
                return {'should_failback': False, 'reason': 'VM master non trouv√©e'}

            # V√©rifier l'√©tat de la VM
            if vm.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                # VM master revenue en ligne !
                Disconnect(si)
                return {
                    'should_failback': True,
                    'reason': f'VM master {replication.virtual_machine.name} revenue en ligne'
                }

            Disconnect(si)
            return {'should_failback': False, 'reason': 'VM master toujours √©teinte'}

        except Exception as e:
            logger.error(f"[FAILBACK-CHECK] Erreur v√©rification auto-failback pour {replication.name}: {e}")
            return {'should_failback': False, 'reason': f'Serveur source inaccessible: {e}'}

    def delete_replicated_vm(self, replication):
        """
        Supprimer la VM r√©pliqu√©e du serveur de destination

        Args:
            replication: Instance VMReplication

        Returns:
            dict: R√©sultat de la suppression avec 'success' (bool) et 'message' (str)
        """
        try:
            logger.info(f"[REPLICATION DELETE] D√©but de la suppression de la VM r√©pliqu√©e: {replication.virtual_machine.name}")

            # Connexion au serveur de destination
            dest_server = replication.destination_server
            logger.info(f"[REPLICATION DELETE] Connexion au serveur de destination: {dest_server.hostname}")

            si = self._connect_to_server(dest_server)

            # Trouver la VM r√©pliqu√©e sur le serveur de destination
            # La VM r√©pliqu√©e a le suffixe "_replica"
            vm_name = replication.virtual_machine.name
            replica_vm_name = f"{vm_name}_replica"
            logger.info(f"[REPLICATION DELETE] Recherche de la VM replica: {replica_vm_name}")

            vm = self._get_vm_by_name(si, replica_vm_name)

            if not vm:
                logger.warning(f"[REPLICATION DELETE] VM replica {replica_vm_name} non trouv√©e sur le serveur de destination")
                Disconnect(si)
                return {
                    'success': True,
                    'message': f'VM replica {replica_vm_name} non trouv√©e sur le serveur de destination (peut-√™tre d√©j√† supprim√©e)'
                }

            # V√©rifier l'√©tat de la VM
            power_state = vm.runtime.powerState
            logger.info(f"[REPLICATION DELETE] √âtat de la VM: {power_state}")

            # Si la VM est allum√©e, l'√©teindre d'abord
            if power_state == vim.VirtualMachinePowerState.poweredOn:
                logger.info(f"[REPLICATION DELETE] Extinction de la VM replica {replica_vm_name}...")
                try:
                    task = vm.PowerOffVM_Task()
                    # Attendre que la t√¢che se termine (timeout 60s)
                    import time
                    timeout = 60
                    elapsed = 0
                    while task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                        time.sleep(1)
                        elapsed += 1
                        if elapsed >= timeout:
                            logger.warning(f"[REPLICATION DELETE] Timeout lors de l'extinction de la VM replica")
                            break

                    if task.info.state == vim.TaskInfo.State.error:
                        logger.error(f"[REPLICATION DELETE] Erreur lors de l'extinction: {task.info.error}")
                    else:
                        logger.info(f"[REPLICATION DELETE] VM replica √©teinte avec succ√®s")
                except Exception as e:
                    logger.warning(f"[REPLICATION DELETE] Erreur lors de l'extinction (la VM sera supprim√©e quand m√™me): {e}")

            # Supprimer la VM
            logger.info(f"[REPLICATION DELETE] Suppression de la VM replica {replica_vm_name}...")
            try:
                task = vm.Destroy_Task()
                # Attendre que la t√¢che se termine (timeout 120s)
                import time
                timeout = 120
                elapsed = 0
                while task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    time.sleep(1)
                    elapsed += 1
                    if elapsed >= timeout:
                        logger.error(f"[REPLICATION DELETE] Timeout lors de la suppression de la VM replica")
                        Disconnect(si)
                        return {
                            'success': False,
                            'message': f'Timeout lors de la suppression de la VM replica {replica_vm_name}'
                        }

                if task.info.state == vim.TaskInfo.State.error:
                    error_msg = str(task.info.error.msg) if task.info.error else 'Erreur inconnue'
                    logger.error(f"[REPLICATION DELETE] Erreur lors de la suppression: {error_msg}")
                    Disconnect(si)
                    return {
                        'success': False,
                        'message': f'Erreur lors de la suppression de la VM replica {replica_vm_name}: {error_msg}'
                    }

                logger.info(f"[REPLICATION DELETE] VM replica {replica_vm_name} supprim√©e avec succ√®s du serveur {dest_server.hostname}")
                Disconnect(si)
                return {
                    'success': True,
                    'message': f'VM replica {replica_vm_name} supprim√©e avec succ√®s du serveur de destination'
                }

            except Exception as e:
                logger.error(f"[REPLICATION DELETE] Exception lors de la suppression de la VM: {e}", exc_info=True)
                Disconnect(si)
                return {
                    'success': False,
                    'message': f'Exception lors de la suppression de la VM replica {replica_vm_name}: {str(e)}'
                }

        except Exception as e:
            logger.error(f"[REPLICATION DELETE] Erreur lors de la connexion ou recherche de la VM: {e}", exc_info=True)
            return {
                'success': False,
                'message': f'Erreur lors de la suppression: {str(e)}'
            }
