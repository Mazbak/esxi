"""
Service pour g√©rer la r√©plication de VMs et le failover entre serveurs ESXi
"""
import logging
import os
import tempfile
import shutil
import requests
import urllib3
import xml.etree.ElementTree as ET
from datetime import datetime
from django.utils import timezone
from pyVim.connect import SmartConnect, Disconnect
from pyVmomi import vim
import ssl
import atexit

from esxi.models import VirtualMachine, ESXiServer
from backups.models import VMReplication, FailoverEvent
from esxi.vmware_service import VMwareService

# D√©sactiver les warnings SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

logger = logging.getLogger(__name__)


class ReplicationService:
    """Service de r√©plication et failover de VMs"""

    def __init__(self):
        self.context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
        self.context.verify_mode = ssl.CERT_NONE

    def _connect_to_server(self, esxi_server):
        """
        √âtablir une connexion √† un serveur ESXi

        Args:
            esxi_server: Instance ESXiServer

        Returns:
            ServiceInstance: Connexion pyVmomi
        """
        try:
            si = SmartConnect(
                host=esxi_server.hostname,
                user=esxi_server.username,
                pwd=esxi_server.password,
                port=esxi_server.port or 443,
                sslContext=self.context
            )
            atexit.register(Disconnect, si)
            return si
        except Exception as e:
            logger.error(f"Erreur connexion √† {esxi_server.hostname}: {e}")
            raise

    def _get_vm_by_name(self, si, vm_name):
        """
        R√©cup√©rer une VM par son nom

        Args:
            si: ServiceInstance
            vm_name: Nom de la VM

        Returns:
            vim.VirtualMachine ou None
        """
        content = si.RetrieveContent()
        container = content.viewManager.CreateContainerView(
            content.rootFolder, [vim.VirtualMachine], True
        )

        for vm in container.view:
            if vm.name == vm_name:
                container.Destroy()
                return vm

        container.Destroy()
        return None

    def _download_vmdk_with_retry(self, url, local_path, esxi_user, esxi_pass, device_url,
                                    downloaded, file_index, total_size, last_lease_update, last_ui_update,
                                    chunk_counter, lease, progress_callback, replication_id):
        """
        T√©l√©charge un fichier VMDK avec syst√®me de retry automatique en cas d'erreur r√©seau
        Supporte la reprise du t√©l√©chargement avec HTTP Range headers
        Utilise un thread de keepalive pour maintenir le lease ESXi actif

        Returns:
            tuple: (bytes_downloaded, last_lease_update, last_ui_update, chunk_counter, file_size)
        """
        import logging
        import threading
        import time
        logger = logging.getLogger(__name__)

        filename = os.path.basename(device_url.targetId)
        max_retries = 3
        retry_count = 0
        download_complete = False
        file_downloaded = 0
        file_size = 0

        # Thread de keepalive pour maintenir le lease actif
        keepalive_stop = threading.Event()
        keepalive_last_progress = [0]  # Liste pour pouvoir modifier dans le thread

        def lease_keepalive_thread():
            """Thread qui met √† jour le lease toutes les 30 secondes pour √©viter l'expiration"""
            logger.info(f"[KEEPALIVE] Thread de keepalive du lease d√©marr√©")
            while not keepalive_stop.is_set():
                try:
                    # Attendre 30 secondes (ou jusqu'√† ce qu'on demande l'arr√™t)
                    if keepalive_stop.wait(timeout=30):
                        break  # Stop demand√©

                    # Mettre √† jour le lease avec la derni√®re progression connue
                    current_progress = keepalive_last_progress[0]
                    lease.HttpNfcLeaseProgress(current_progress)
                    logger.debug(f"[KEEPALIVE] Lease mis √† jour: {current_progress}%")

                except Exception as e:
                    logger.warning(f"[KEEPALIVE] Erreur lors de la mise √† jour du lease: {e}")

            logger.info(f"[KEEPALIVE] Thread de keepalive arr√™t√©")

        # D√©marrer le thread de keepalive
        keepalive_thread = threading.Thread(target=lease_keepalive_thread, daemon=True)
        keepalive_thread.start()

        try:
            while retry_count <= max_retries and not download_complete:
                download_start_time = time.time()
                last_chunk_time = time.time()

                try:
                    # V√©rifier si un t√©l√©chargement partiel existe (pour reprise)
                    if os.path.exists(local_path) and os.path.getsize(local_path) > 0 and retry_count > 0:
                        # Reprise du t√©l√©chargement
                        bytes_already_downloaded = os.path.getsize(local_path)
                        file_downloaded = bytes_already_downloaded
                        logger.info(f"[REPLICATION] üîÑ Reprise √† {bytes_already_downloaded / (1024*1024):.1f} MB (tentative {retry_count + 1}/{max_retries + 1})")

                        response = requests.get(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            stream=True,
                            headers={'Range': f'bytes={bytes_already_downloaded}-'},
                            timeout=(10, 120)  # 10s connexion, 120s lecture (r√©duit de 300s)
                        )
                        response.raise_for_status()

                        file_mode = 'ab'  # Append mode
                        file_size_from_header = int(response.headers.get('content-length', 0))
                        if file_size_from_header > 0:
                            file_size = bytes_already_downloaded + file_size_from_header
                    else:
                        # Nouveau t√©l√©chargement
                        bytes_already_downloaded = 0
                        if retry_count > 0:
                            logger.info(f"[REPLICATION] üîÑ Nouvelle tentative {retry_count + 1}/{max_retries + 1}")

                        response = requests.get(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            stream=True,
                            timeout=(10, 120)  # 10s connexion, 120s lecture
                        )
                        response.raise_for_status()

                        file_mode = 'wb'  # Write mode
                        file_size = int(response.headers.get('content-length', 0))
                        file_downloaded = 0

                    # Si file_size = 0, utiliser estimation bas√©e sur targetSize
                    if file_size == 0 and hasattr(device_url, 'targetSize') and device_url.targetSize > 0:
                        file_size = device_url.targetSize
                        logger.info(f"[REPLICATION] Utilisation targetSize: {file_size / (1024*1024):.2f} MB")

                    with open(local_path, file_mode) as f:
                        chunk_size = 32768  # 32KB chunks (r√©duit de 64KB pour plus de callbacks)
                        chunks_received = 0

                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                # V√©rifier annulation
                                if replication_id:
                                    from django.core.cache import cache
                                    progress_data = cache.get(f'replication_progress_{replication_id}')
                                    if progress_data and progress_data.get('status') == 'cancelled':
                                        logger.info(f"[REPLICATION] Annulation d√©tect√©e")
                                        raise Exception("R√©plication annul√©e par l'utilisateur")

                                f.write(chunk)
                                downloaded += len(chunk)
                                file_downloaded += len(chunk)
                                chunk_counter += 1
                                chunks_received += 1

                                # Logger le temps entre chunks toutes les 100 chunks (~3.2 MB)
                                current_time = time.time()
                                if chunks_received % 100 == 0:
                                    time_since_last = current_time - last_chunk_time
                                    speed_mbps = (100 * chunk_size / 1024 / 1024) / time_since_last if time_since_last > 0 else 0
                                    logger.debug(f"[REPLICATION] 100 chunks re√ßus en {time_since_last:.2f}s ({speed_mbps:.2f} MB/s)")
                                    last_chunk_time = current_time

                                # Mise √† jour du lease (pour les logs et le keepalive thread)
                                if total_size > 0:
                                    lease_progress = int((downloaded / total_size) * 100)
                                else:
                                    lease_progress = int((file_downloaded / file_size) * 100) if file_size > 0 else 0

                                # Mettre √† jour la progression pour le keepalive thread
                                keepalive_last_progress[0] = lease_progress

                                # Calcul progression UI (25-60%)
                                if total_size > 0:
                                    progress_pct = 25 + (35 * downloaded / total_size)
                                else:
                                    if file_size > 0:
                                        progress_pct = 25 + (35 * file_downloaded / file_size)
                                    else:
                                        import math
                                        downloaded_mb = downloaded / (1024 * 1024)
                                        if downloaded_mb < 100:
                                            progress_pct = 25 + (downloaded_mb * 0.05)
                                        elif downloaded_mb < 1000:
                                            progress_pct = 30 + (20 * math.log(downloaded_mb / 100) / math.log(10))
                                        else:
                                            progress_pct = min(50 + (10 * math.log(downloaded_mb / 1000) / math.log(10)), 60)

                                # Callback UI
                                if (progress_pct >= last_ui_update + 0.5) or (chunk_counter >= 10):
                                    if progress_callback:
                                        downloaded_mb = downloaded / (1024 * 1024)
                                        file_mb = file_downloaded / (1024 * 1024)
                                        file_size_mb = file_size / (1024 * 1024)
                                        if total_size > 0:
                                            total_mb = total_size / (1024 * 1024)
                                            progress_callback(progress_pct, 'exporting',
                                                f'Export VMDK: {downloaded_mb:.1f}/{total_mb:.1f} MB ({int(progress_pct)}%)')
                                        elif file_size > 0:
                                            progress_callback(progress_pct, 'exporting',
                                                f'Export {filename}: {file_mb:.1f}/{file_size_mb:.1f} MB ({int(progress_pct)}%)')
                                        else:
                                            progress_callback(progress_pct, 'exporting',
                                                f'Export {filename}: {file_mb:.1f} MB t√©l√©charg√©s...')
                                        last_ui_update = progress_pct
                                        chunk_counter = 0

                    # T√©l√©chargement r√©ussi!
                    download_complete = True
                    total_time = time.time() - download_start_time
                    avg_speed = (file_downloaded / 1024 / 1024) / total_time if total_time > 0 else 0
                    logger.info(f"[REPLICATION] ‚úÖ {filename} t√©l√©charg√© ({file_downloaded / (1024*1024):.1f} MB en {total_time:.1f}s, {avg_speed:.2f} MB/s)")

                except (requests.exceptions.ChunkedEncodingError,
                        requests.exceptions.ConnectionError,
                        requests.exceptions.Timeout,
                        ConnectionResetError) as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        logger.error(f"[REPLICATION] ‚ùå √âchec apr√®s {max_retries + 1} tentatives: {e}")
                        raise Exception(f"T√©l√©chargement √©chou√© apr√®s {max_retries + 1} tentatives: {e}")

                    logger.warning(f"[REPLICATION] ‚ö†Ô∏è  Erreur ({e}), reprise dans 3s...")
                    time.sleep(3)

        finally:
            # IMPORTANT: Arr√™ter le thread de keepalive
            keepalive_stop.set()
            keepalive_thread.join(timeout=5)  # Attendre max 5 secondes

        return (downloaded, last_lease_update, last_ui_update, chunk_counter, file_size)

    def _export_vm_to_ovf(self, si, vm_name, export_path, esxi_host, esxi_user, esxi_pass, progress_callback=None, replication_id=None):
        """
        Exporter une VM en format OVF en utilisant HttpNfcLease API
        Version simplifi√©e sans d√©pendances sur les mod√®les Django

        Args:
            si: ServiceInstance pyVmomi
            vm_name: Nom de la VM √† exporter
            export_path: Chemin o√π exporter l'OVF
            esxi_host: Hostname du serveur ESXi
            esxi_user: Username ESXi
            esxi_pass: Password ESXi
            progress_callback: Callback optionnel pour progression
            replication_id: ID de r√©plication pour v√©rifier l'annulation

        Returns:
            str: Chemin vers le fichier OVF g√©n√©r√©
        """
        vm_obj = self._get_vm_by_name(si, vm_name)
        if not vm_obj:
            raise Exception(f"VM {vm_name} non trouv√©e")

        logger.info(f"[REPLICATION] D√©but export OVF de {vm_name}")

        # Cr√©er un lease d'export
        lease = vm_obj.ExportVm()

        # Attendre que le lease soit pr√™t
        while lease.state == vim.HttpNfcLease.State.initializing:
            pass

        if lease.state != vim.HttpNfcLease.State.ready:
            raise Exception(f"Export lease √©chou√©: {lease.state}")

        try:
            # T√©l√©charger les fichiers VMDK
            vmdk_files = []
            device_urls = lease.info.deviceUrl

            # Calculer total_size depuis l'API si disponible
            total_size = sum(d.targetSize for d in device_urls if hasattr(d, 'targetSize'))

            # Si total_size = 0 (m√©tadonn√©es incompl√®tes), faire une passe pour r√©cup√©rer les tailles r√©elles
            if total_size == 0:
                logger.info(f"[REPLICATION] targetSize non disponible, r√©cup√©ration tailles r√©elles via HTTP HEAD...")
                for device_url in device_urls:
                    if not device_url.url.endswith('.vmdk'):
                        continue
                    url = device_url.url.replace('*', esxi_host)
                    try:
                        # HEAD request pour obtenir Content-Length sans t√©l√©charger
                        head_response = requests.head(
                            url,
                            auth=(esxi_user, esxi_pass),
                            verify=False,
                            timeout=10
                        )
                        file_size = int(head_response.headers.get('content-length', 0))
                        total_size += file_size
                    except Exception as e:
                        logger.warning(f"[REPLICATION] Impossible de r√©cup√©rer la taille de {url}: {e}")

                logger.info(f"[REPLICATION] Taille totale calcul√©e depuis HTTP: {total_size / (1024*1024):.2f} MB")
            else:
                logger.info(f"[REPLICATION] Taille totale depuis API: {total_size / (1024*1024):.2f} MB")

            downloaded = 0
            last_lease_update = 0  # Dernier pourcentage o√π on a mis √† jour le lease
            last_ui_update = 0  # Dernier pourcentage o√π on a mis √† jour l'UI
            chunk_counter = 0  # Compteur de chunks

            file_index = 0
            for device_url in device_urls:
                if not device_url.url.endswith('.vmdk'):
                    continue

                # Remplacer * par l'IP du serveur ESXi
                url = device_url.url.replace('*', esxi_host)
                filename = os.path.basename(device_url.targetId)
                local_path = os.path.join(export_path, filename)

                logger.info(f"[REPLICATION] T√©l√©chargement {filename}...")

                # Utiliser la m√©thode avec retry automatique et reprise
                downloaded, last_lease_update, last_ui_update, chunk_counter, file_size = self._download_vmdk_with_retry(
                    url=url,
                    local_path=local_path,
                    esxi_user=esxi_user,
                    esxi_pass=esxi_pass,
                    device_url=device_url,
                    downloaded=downloaded,
                    file_index=file_index,
                    total_size=total_size,
                    last_lease_update=last_lease_update,
                    last_ui_update=last_ui_update,
                    chunk_counter=chunk_counter,
                    lease=lease,
                    progress_callback=progress_callback,
                    replication_id=replication_id
                )

                vmdk_files.append({
                    'path': local_path,
                    'filename': filename,
                    'size': file_size
                })
                logger.info(f"[REPLICATION] {filename} t√©l√©charg√©: {file_size / (1024*1024):.2f} MB")
                file_index += 1

            # Cr√©er le descripteur OVF
            ovf_path = os.path.join(export_path, f"{vm_name}.ovf")
            self._create_simple_ovf_descriptor(vm_obj, vmdk_files, ovf_path)

            # Compl√©ter le lease seulement s'il est encore actif
            try:
                if lease.state == vim.HttpNfcLease.State.ready:
                    lease.HttpNfcLeaseComplete()
                    logger.info(f"[REPLICATION] Lease compl√©t√© avec succ√®s")
            except Exception as lease_err:
                logger.warning(f"[REPLICATION] Impossible de compl√©ter le lease (probablement d√©j√† ferm√©): {lease_err}")

            logger.info(f"[REPLICATION] Export OVF termin√©: {ovf_path}")
            return ovf_path

        except Exception as e:
            # Annuler le lease seulement s'il est encore actif
            try:
                if lease.state in [vim.HttpNfcLease.State.ready, vim.HttpNfcLease.State.initializing]:
                    lease.HttpNfcLeaseAbort()
            except:
                pass  # Ignorer les erreurs lors de l'annulation
            raise

    def _create_simple_ovf_descriptor(self, vm_obj, vmdk_files, ovf_path):
        """Cr√©er un descripteur OVF simplifi√©"""
        # Cr√©er la structure OVF de base
        ovf_ns = "http://schemas.dmtf.org/ovf/envelope/1"
        rasd_ns = "http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_ResourceAllocationSettingData"
        vssd_ns = "http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_VirtualSystemSettingData"

        ET.register_namespace('ovf', ovf_ns)
        ET.register_namespace('rasd', rasd_ns)
        ET.register_namespace('vssd', vssd_ns)

        root = ET.Element(f"{{{ovf_ns}}}Envelope")

        # R√©f√©rences
        references = ET.SubElement(root, f"{{{ovf_ns}}}References")
        for vmdk in vmdk_files:
            file_elem = ET.SubElement(references, f"{{{ovf_ns}}}File")
            file_elem.set(f"{{{ovf_ns}}}href", vmdk['filename'])
            file_elem.set(f"{{{ovf_ns}}}id", vmdk['filename'])
            file_elem.set(f"{{{ovf_ns}}}size", str(vmdk['size']))

        # DiskSection
        disk_section = ET.SubElement(root, f"{{{ovf_ns}}}DiskSection")
        ET.SubElement(disk_section, f"{{{ovf_ns}}}Info").text = "Virtual disk information"

        for i, vmdk in enumerate(vmdk_files):
            disk = ET.SubElement(disk_section, f"{{{ovf_ns}}}Disk")
            disk.set(f"{{{ovf_ns}}}diskId", f"vmdisk{i+1}")
            disk.set(f"{{{ovf_ns}}}fileRef", vmdk['filename'])
            disk.set(f"{{{ovf_ns}}}capacity", str(vmdk['size']))

        # VirtualSystem
        vs = ET.SubElement(root, f"{{{ovf_ns}}}VirtualSystem")
        vs.set(f"{{{ovf_ns}}}id", vm_obj.name)
        ET.SubElement(vs, f"{{{ovf_ns}}}Info").text = f"Virtual Machine {vm_obj.name}"
        ET.SubElement(vs, f"{{{ovf_ns}}}Name").text = vm_obj.name

        # √âcrire le fichier OVF
        tree = ET.ElementTree(root)
        tree.write(ovf_path, encoding='utf-8', xml_declaration=True)

        logger.info(f"[REPLICATION] Descripteur OVF cr√©√©: {ovf_path}")

    def replicate_vm(self, replication, progress_callback=None, replication_id=None):
        """
        Effectuer une r√©plication compl√®te de VM

        Processus :
        1. Exporter la VM source en OVF (temporaire)
        2. D√©ployer sur le serveur destination avec suffix "_replica"
        3. La VM replica est pr√™te pour le failover instantan√©

        Args:
            replication: Instance VMReplication
            progress_callback: Fonction callback pour la progression (optionnel)
            replication_id: ID de r√©plication pour v√©rifier l'annulation (optionnel)

        Returns:
            dict: R√©sultat de la r√©plication
        """
        temp_dir = None
        try:
            import time
            start_time = timezone.now()
            logger.info(f"[REPLICATION] D√©marrage: {replication.name}")

            if progress_callback:
                progress_callback(0, 'starting', 'D√©marrage de la r√©plication...')

            source_server = replication.get_source_server
            destination_server = replication.destination_server
            vm_name = replication.virtual_machine.name
            replica_vm_name = f"{vm_name}_replica"

            # Progression graduelle 0-2%
            if progress_callback:
                progress_callback(1, 'initializing', 'Initialisation de la r√©plication...')
                time.sleep(0.3)
                progress_callback(2, 'initializing', 'V√©rification des serveurs...')

            # V√©rifier si la VM replica existe d√©j√† (3-8%)
            logger.info(f"[REPLICATION] Connexion au serveur destination: {destination_server.hostname}")
            if progress_callback:
                progress_callback(3, 'connecting', f'Connexion au serveur destination...')
                time.sleep(0.2)
                progress_callback(5, 'connecting', f'√âtablissement de la connexion √† {destination_server.hostname}...')

            dest_si = self._connect_to_server(destination_server)

            if progress_callback:
                progress_callback(7, 'checking', 'V√©rification de la VM replica existante...')

            existing_replica = self._get_vm_by_name(dest_si, replica_vm_name)

            if existing_replica:
                logger.info(f"[REPLICATION] VM replica existe d√©j√†: {replica_vm_name}")
                logger.info(f"[REPLICATION] Suppression de l'ancienne replica pour mise √† jour...")

                if progress_callback:
                    progress_callback(8, 'cleaning', 'Pr√©paration de la suppression...')
                    time.sleep(0.2)
                    progress_callback(10, 'cleaning', 'Suppression de l\'ancienne replica...')

                # Arr√™ter la VM si elle tourne
                if existing_replica.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                    if progress_callback:
                        progress_callback(11, 'cleaning', 'Arr√™t de l\'ancienne VM replica...')
                    power_off_task = existing_replica.PowerOffVM_Task()
                    while power_off_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                        time.sleep(0.1)

                # Supprimer la VM
                if progress_callback:
                    progress_callback(13, 'cleaning', 'Suppression des fichiers de la replica...')
                destroy_task = existing_replica.Destroy_Task()
                while destroy_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    time.sleep(0.1)

                logger.info(f"[REPLICATION] Ancienne replica supprim√©e")
                if progress_callback:
                    progress_callback(15, 'cleaned', 'Ancienne replica supprim√©e')
            else:
                # Pas de replica existante, progression rapide
                if progress_callback:
                    progress_callback(10, 'checking', 'Aucune replica existante trouv√©e')
                    time.sleep(0.2)
                    progress_callback(15, 'ready', 'Pr√™t pour la r√©plication')

            # Cr√©er un r√©pertoire temporaire pour l'export OVF (16-18%)
            if progress_callback:
                progress_callback(16, 'preparing', 'Cr√©ation du r√©pertoire temporaire...')

            temp_dir = tempfile.mkdtemp(prefix='replication_')
            logger.info(f"[REPLICATION] R√©pertoire temporaire: {temp_dir}")

            if progress_callback:
                progress_callback(18, 'preparing', 'Pr√©paration de l\'export OVF...')
                time.sleep(0.2)

            # Se connecter au serveur source pour l'export (19-24%)
            logger.info(f"[REPLICATION] Connexion au serveur source: {source_server.hostname}")
            if progress_callback:
                progress_callback(19, 'connecting', f'Connexion au serveur source...')
                time.sleep(0.2)
                progress_callback(21, 'connecting', f'√âtablissement de la connexion √† {source_server.hostname}...')

            source_si = self._connect_to_server(source_server)

            if progress_callback:
                progress_callback(23, 'connected', 'Serveur source connect√©')
                time.sleep(0.2)
                progress_callback(24, 'preparing', f'Pr√©paration de l\'export de {vm_name}...')

            # Exporter la VM source en OVF (25% ‚Üí 60%)
            logger.info(f"[REPLICATION] Export de la VM source: {vm_name}")
            if progress_callback:
                progress_callback(25, 'exporting', f'Export de la VM {vm_name} en cours...')

            ovf_path = self._export_vm_to_ovf(
                source_si,
                vm_name,
                temp_dir,
                source_server.hostname,
                source_server.username,
                source_server.password,
                progress_callback,
                replication_id
            )
            logger.info(f"[REPLICATION] Export OVF termin√©: {ovf_path}")

            if progress_callback:
                progress_callback(60, 'exported', 'Export OVF termin√© avec succ√®s')

            # D√©connexion du serveur source
            Disconnect(source_si)

            # D√©ployer sur le serveur destination avec le nom "_replica" (65%)
            logger.info(f"[REPLICATION] D√©ploiement sur serveur destination: {destination_server.hostname}")
            if progress_callback:
                progress_callback(65, 'deploying', f'D√©ploiement de la replica sur {destination_server.hostname}...')

            vmware_service = VMwareService(
                host=destination_server.hostname,
                user=destination_server.username,
                password=destination_server.password,
                port=destination_server.port or 443
            )

            # SE CONNECTER au serveur de destination
            logger.info(f"[REPLICATION] Connexion au serveur de destination {destination_server.hostname}...")
            if not vmware_service.connect():
                raise Exception(f"Impossible de se connecter au serveur de destination {destination_server.hostname}")
            logger.info(f"[REPLICATION] ‚úÖ Connect√© au serveur de destination")

            # R√©cup√©rer le premier datastore disponible (70%)
            if progress_callback:
                progress_callback(70, 'deploying', 'Recherche du datastore de destination...')

            logger.info(f"[REPLICATION] Appel de get_datastores() sur {destination_server.hostname}")
            try:
                datastores_info = vmware_service.get_datastores()
                logger.info(f"[REPLICATION] R√©sultat get_datastores(): {datastores_info}")
            except Exception as ds_err:
                logger.error(f"[REPLICATION] Erreur lors de get_datastores(): {ds_err}", exc_info=True)
                raise Exception(f"Impossible de r√©cup√©rer les datastores: {ds_err}")

            # datastores_info est une LISTE de datastores, pas un dictionnaire
            if not datastores_info or len(datastores_info) == 0:
                logger.error(f"[REPLICATION] datastores_info est vide: {datastores_info}")
                raise Exception("Aucun datastore disponible sur le serveur destination")

            # Prendre le premier datastore accessible
            dest_datastore = datastores_info[0]['name']
            logger.info(f"[REPLICATION] Datastore destination s√©lectionn√©: {dest_datastore} (capacit√©: {datastores_info[0]['capacity_gb']} GB, libre: {datastores_info[0]['free_space_gb']} GB)")

            # D√©ployer l'OVF (75% ‚Üí 90%)
            if progress_callback:
                progress_callback(75, 'deploying', 'D√©ploiement de l\'OVF en cours...')

            # Cr√©er un callback wrapper pour mapper 0-100% du d√©ploiement vers 75-90% de la progression totale
            def deploy_progress_callback(deploy_pct, status, message):
                if progress_callback:
                    # Mapper 0-100% du d√©ploiement vers 75-90% de la progression totale
                    total_pct = 75 + (15 * deploy_pct / 100)
                    progress_callback(total_pct, status, message)

            deploy_success = vmware_service.deploy_ovf(
                ovf_path=ovf_path,
                vm_name=replica_vm_name,
                datastore_name=dest_datastore,
                network_name='VM Network',
                power_on=False,  # Ne pas d√©marrer la replica automatiquement
                progress_callback=deploy_progress_callback
            )

            if not deploy_success:
                raise Exception("√âchec du d√©ploiement OVF sur le serveur destination")

            logger.info(f"[REPLICATION] VM replica d√©ploy√©e: {replica_vm_name}")

            if progress_callback:
                progress_callback(90, 'deployed', f'VM replica {replica_vm_name} d√©ploy√©e')
                time.sleep(0.3)
                progress_callback(92, 'finalizing', 'V√©rification de la VM replica...')
                time.sleep(0.2)

            # Nettoyer le r√©pertoire temporaire (93-96%)
            if progress_callback:
                progress_callback(93, 'cleaning', 'D√©but du nettoyage...')
                time.sleep(0.2)
                progress_callback(94, 'cleaning', 'Suppression des fichiers temporaires...')

            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                logger.info(f"[REPLICATION] R√©pertoire temporaire nettoy√©")

            if progress_callback:
                progress_callback(96, 'cleaned', 'Nettoyage termin√©')
                time.sleep(0.2)

            # Mettre √† jour la r√©plication (97-99%)
            if progress_callback:
                progress_callback(97, 'updating', 'Mise √† jour des m√©tadonn√©es de r√©plication...')

            end_time = timezone.now()
            duration = (end_time - start_time).total_seconds()

            replication.last_replication_at = end_time
            replication.last_replication_duration_seconds = int(duration)
            replication.status = 'active'
            replication.save()

            logger.info(f"[REPLICATION] Termin√©e: {replication.name} ({duration:.2f}s)")

            if progress_callback:
                progress_callback(98, 'saving', 'Enregistrement de l\'√©tat de r√©plication...')
                time.sleep(0.2)
                progress_callback(99, 'disconnecting', 'D√©connexion des serveurs...')

            # D√©connexion
            Disconnect(dest_si)

            if progress_callback:
                time.sleep(0.3)
                progress_callback(100, 'completed', f'‚úÖ R√©plication termin√©e avec succ√®s en {duration:.1f}s')

            # D√©connecter le service VMware de destination
            try:
                vmware_service.disconnect()
                logger.info(f"[REPLICATION] D√©connect√© du serveur de destination")
            except:
                pass

            return {
                'success': True,
                'duration_seconds': duration,
                'message': f"R√©plication de {vm_name} termin√©e avec succ√®s. VM replica: {replica_vm_name}"
            }

        except Exception as e:
            logger.error(f"[REPLICATION] Erreur: {replication.name}: {e}")

            if progress_callback:
                progress_callback(-1, 'error', f'Erreur: {str(e)}')

            # D√©connecter le service VMware de destination si cr√©√©
            try:
                if 'vmware_service' in locals():
                    vmware_service.disconnect()
                    logger.info(f"[REPLICATION] D√©connect√© du serveur de destination (erreur)")
            except:
                pass

            # Nettoyer le r√©pertoire temporaire en cas d'erreur
            if temp_dir and os.path.exists(temp_dir):
                try:
                    shutil.rmtree(temp_dir)
                except:
                    pass

            replication.status = 'error'
            replication.save()

            return {
                'success': False,
                'error': str(e),
                'message': f"Erreur lors de la r√©plication: {e}"
            }

    def execute_failover(self, failover_event, test_mode=False):
        """
        Ex√©cuter un failover (basculement)

        Args:
            failover_event: Instance FailoverEvent
            test_mode: Si True, ne pas arr√™ter la VM source

        Returns:
            dict: R√©sultat du failover
        """
        try:
            logger.info(f"D√©marrage failover: {failover_event.id}")
            failover_event.status = 'in_progress'
            failover_event.save()

            replication = failover_event.replication
            source_server = replication.get_source_server
            destination_server = replication.destination_server
            vm_name = replication.virtual_machine.name

            # Se connecter aux serveurs
            logger.info(f"Connexion au serveur source: {source_server.hostname}")
            source_si = self._connect_to_server(source_server)

            logger.info(f"Connexion au serveur destination: {destination_server.hostname}")
            dest_si = self._connect_to_server(destination_server)

            # R√©cup√©rer les VMs
            source_vm = self._get_vm_by_name(source_si, vm_name)
            dest_vm = self._get_vm_by_name(dest_si, f"{vm_name}_replica")

            if not dest_vm:
                # Si la VM de destination n'existe pas, utiliser le m√™me nom
                dest_vm = self._get_vm_by_name(dest_si, vm_name)

            if not dest_vm:
                raise Exception(f"VM de destination non trouv√©e sur {destination_server.hostname}")

            # Arr√™ter la VM source (sauf en mode test)
            if source_vm and source_vm.runtime.powerState == vim.VirtualMachinePowerState.poweredOn:
                if not test_mode:
                    logger.info(f"Arr√™t de la VM source: {vm_name}")
                    power_off_task = source_vm.PowerOffVM_Task()

                    # Attendre la fin de l'arr√™t
                    while power_off_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                        pass

                    if power_off_task.info.state == vim.TaskInfo.State.error:
                        raise Exception(f"Erreur arr√™t VM source: {power_off_task.info.error}")

                    failover_event.source_vm_powered_off = True
                    failover_event.save()
                    logger.info(f"VM source arr√™t√©e: {vm_name}")
                else:
                    logger.info(f"Mode test: VM source non arr√™t√©e")

            # D√©marrer la VM de destination
            if dest_vm.runtime.powerState != vim.VirtualMachinePowerState.poweredOn:
                logger.info(f"D√©marrage de la VM de destination: {vm_name}")
                power_on_task = dest_vm.PowerOnVM_Task()

                # Attendre le d√©marrage
                while power_on_task.info.state not in [vim.TaskInfo.State.success, vim.TaskInfo.State.error]:
                    pass

                if power_on_task.info.state == vim.TaskInfo.State.error:
                    raise Exception(f"Erreur d√©marrage VM destination: {power_on_task.info.error}")

                failover_event.destination_vm_powered_on = True
                failover_event.save()
                logger.info(f"VM de destination d√©marr√©e: {vm_name}")
            else:
                logger.info(f"VM de destination d√©j√† d√©marr√©e: {vm_name}")
                failover_event.destination_vm_powered_on = True
                failover_event.save()

            # Marquer le failover comme termin√©
            failover_event.status = 'completed'
            failover_event.completed_at = timezone.now()
            failover_event.save()

            # D√©connexion
            Disconnect(source_si)
            Disconnect(dest_si)

            logger.info(f"Failover termin√© avec succ√®s: {failover_event.id}")

            return {
                'success': True,
                'message': f"Failover de {vm_name} termin√© avec succ√®s",
                'source_powered_off': failover_event.source_vm_powered_off,
                'destination_powered_on': failover_event.destination_vm_powered_on
            }

        except Exception as e:
            logger.error(f"Erreur lors du failover {failover_event.id}: {e}")

            failover_event.status = 'failed'
            failover_event.error_message = str(e)
            failover_event.completed_at = timezone.now()
            failover_event.save()

            return {
                'success': False,
                'error': str(e),
                'message': f"Erreur lors du failover: {e}"
            }

    def check_and_trigger_auto_failover(self, replication):
        """
        V√©rifier si un failover automatique doit √™tre d√©clench√©

        Args:
            replication: Instance VMReplication

        Returns:
            dict: R√©sultat de la v√©rification
        """
        if replication.failover_mode != 'automatic':
            return {'should_failover': False, 'reason': 'Mode automatique non activ√©'}

        # V√©rifier si le serveur source est indisponible
        source_server = replication.get_source_server

        try:
            # Tenter de se connecter au serveur source
            si = self._connect_to_server(source_server)

            # V√©rifier la VM
            vm = self._get_vm_by_name(si, replication.virtual_machine.name)

            if not vm:
                return {'should_failover': False, 'reason': 'VM non trouv√©e'}

            # V√©rifier l'√©tat de la VM
            if vm.runtime.powerState != vim.VirtualMachinePowerState.poweredOn:
                # VM √©teinte, v√©rifier le d√©lai
                if replication.last_replication_at:
                    minutes_since_last = (timezone.now() - replication.last_replication_at).total_seconds() / 60

                    if minutes_since_last >= replication.auto_failover_threshold_minutes:
                        return {
                            'should_failover': True,
                            'reason': f'VM √©teinte depuis {minutes_since_last:.0f} minutes'
                        }

            Disconnect(si)
            return {'should_failover': False, 'reason': 'VM en fonctionnement normal'}

        except Exception as e:
            logger.error(f"Erreur v√©rification auto-failover pour {replication.name}: {e}")

            # Serveur source inaccessible
            if replication.last_replication_at:
                minutes_since_last = (timezone.now() - replication.last_replication_at).total_seconds() / 60

                if minutes_since_last >= replication.auto_failover_threshold_minutes:
                    return {
                        'should_failover': True,
                        'reason': f'Serveur source inaccessible depuis {minutes_since_last:.0f} minutes'
                    }

            return {'should_failover': False, 'reason': f'Serveur source inaccessible (en attente du d√©lai): {e}'}
